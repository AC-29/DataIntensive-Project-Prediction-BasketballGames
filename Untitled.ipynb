{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@6a4bcc6f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@6a4bcc6f"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, Dataset, Row, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "val spark = SparkSession.builder.master(\"local[*]\").appName(\"dataProcessing\").getOrCreate()\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.41,0.17,2.99,0.371,5.32,1.98,0.428,14.09,6.02,0.887,3.6,3.2,81,2284.0,0.46,2.16,1242,17.22,3.44,2002,1.56,3.07]\n",
      "[2.99,0.47,6.2,0.35,0.74,0.26,0.478,14.6,6.99,0.841,6.68,5.62,81,2281.0,2.16,2.96,1018,19.85,8.36,2002,1.07,2.62]\n",
      "[2.97,0.38,5.38,0.342,3.81,1.3,0.432,18.09,7.81,0.876,4.43,3.88,69,2253.0,1.25,2.65,907,20.81,6.62,2002,1.32,3.59]\n",
      "[0.9,3.23,5.59,0.0,0.0,0.0,0.464,7.35,3.41,0.72,2.64,1.9,81,1869.0,1.9,3.35,964,8.72,7.49,2002,0.69,1.69]\n",
      "[1.36,0.36,2.53,0.381,1.15,0.44,0.495,6.4,3.16,0.778,1.23,0.96,73,1584.0,1.18,2.38,1323,7.73,3.71,2002,0.68,0.95]\n",
      "[1.86,0.2,2.89,0.354,2.08,0.74,0.427,8.53,3.64,0.784,2.13,1.67,76,1490.0,0.82,1.92,1244,9.7,3.71,2002,0.93,1.42]\n",
      "[0.5,0.39,2.95,0.0,0.02,0.0,0.468,3.99,1.87,0.638,1.68,1.07,82,1092.0,1.9,2.05,958,4.8,4.85,2002,0.4,0.74]\n",
      "[1.11,0.22,2.33,0.154,1.44,0.22,0.302,4.78,1.44,0.75,1.78,1.33,9,1003.0,1.11,2.22,1190,4.44,3.44,2002,0.11,0.67]\n",
      "[1.5,0.08,1.58,0.241,1.21,0.29,0.364,3.67,1.33,0.773,0.92,0.71,24,850.0,0.21,1.17,1047,3.67,1.79,2002,0.5,1.04]\n",
      "[0.17,0.6,2.34,0.0,0.0,0.0,0.421,4.54,1.91,0.634,1.17,0.74,35,772.0,1.34,2.26,1154,4.57,3.69,2002,0.46,0.71]\n",
      "[0.51,0.25,1.07,0.0,0.04,0.0,0.447,2.12,0.95,0.481,1.05,0.51,75,739.0,0.97,1.69,1026,2.4,2.04,2002,0.21,0.87]\n",
      "[1.4,0.11,0.72,0.1,0.19,0.02,0.364,2.08,0.75,0.727,1.04,0.75,53,628.0,0.36,0.96,1256,2.28,1.08,2002,0.36,0.64]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "path = /home/fernando/Desktop/DataIntensive-Project-Prediction-BasketballGames\n",
       "seasons = Range(2002)\n",
       "teams = Range(1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Range(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.File\n",
    "import scala.io.Source\n",
    "\n",
    "val path = System.getProperty(\"user.dir\")\n",
    "val seasons = 2002 to 2002\n",
    "val teams = 1 to 1\n",
    "\n",
    "for (i <- seasons){\n",
    "    for (j <- teams){\n",
    "        val file = path + \"/season_averages/\" + i + \"/\" + j + \".json\"\n",
    "        try{\n",
    "            var df_stats = spark.read.json(file)\n",
    "            var elem = df_stats.select(explode($\"data\").as(\"data_flat\"))\n",
    "            var minutes = elem.select(\"data_flat.min\")\n",
    "            val split_min = elem.withColumn(\"ast\", $\"data_flat.ast\")\n",
    "            .withColumn(\"blk\", $\"data_flat.blk\")\n",
    "            .withColumn(\"dreb\", $\"data_flat.dreb\")\n",
    "            .withColumn(\"fg3_pct\", $\"data_flat.fg3_pct\")\n",
    "            .withColumn(\"fg3a\", $\"data_flat.fg3a\")\n",
    "            .withColumn(\"fg3m\", $\"data_flat.fg3m\")\n",
    "            .withColumn(\"fg_pct\", $\"data_flat.fg_pct\")\n",
    "            .withColumn(\"fga\", $\"data_flat.fga\")\n",
    "            .withColumn(\"fgm\", $\"data_flat.fgm\")\n",
    "            .withColumn(\"ft_pct\", $\"data_flat.ft_pct\")\n",
    "            .withColumn(\"fta\", $\"data_flat.fta\")\n",
    "            .withColumn(\"ftm\", $\"data_flat.ftm\")\n",
    "            .withColumn(\"games_played\", $\"data_flat.games_played\")\n",
    "            .withColumn(\"seconds\", split($\"data_flat.min\", \":\")(0) * 60 + split($\"data_flat.min\", \":\")(1))\n",
    "            .withColumn(\"oreb\", $\"data_flat.oreb\")\n",
    "            .withColumn(\"pf\", $\"data_flat.pf\")\n",
    "            .withColumn(\"player_id\", $\"data_flat.player_id\")\n",
    "            .withColumn(\"pts\", $\"data_flat.pts\")\n",
    "            .withColumn(\"reb\", $\"data_flat.reb\")\n",
    "            .withColumn(\"season\", $\"data_flat.season\")\n",
    "            .withColumn(\"stl\", $\"data_flat.stl\")\n",
    "            .withColumn(\"turnover\", $\"data_flat.turnover\")\n",
    "            .drop($\"data_flat\")\n",
    "            \n",
    "            \n",
    "            val best_12 = split_min.orderBy(desc(\"seconds\")).limit(12)\n",
    "            /*\n",
    "            val best_12_struct = best_12.withColumn(\"data\", struct(col(\"ast\"), col(\"blk\"), col(\"dreb\"), col(\"fg3_pct\"), col(\"fg3a\"), \n",
    "                                                                   col(\"fg3m\"), col(\"fg_pct\"), col(\"fga\"), col(\"fgm\"), \n",
    "                                                                   col(\"ft_pct\"), col(\"fta\"), col(\"ftm\"), col(\"games_played\"), \n",
    "                                                                   col(\"seconds\"), col(\"oreb\"), col(\"pf\"), col(\"player_id\"), \n",
    "                                                                   col(\"pts\"), col(\"reb\"), col(\"season\"), col(\"stl\"), col(\"turnover\")))\n",
    "            */\n",
    "            val test = best_12.collect()\n",
    "            test.foreach(println)\n",
    "            \n",
    "            // val best_12_data = best_12_struct.select(\"data\")\n",
    "            // best_12_data.show()\n",
    "            // best_12_data.write.mode(\"overwrite\").format(\"json\").save(path + \"/season_averages/\" + i + \"/\" + j)\n",
    "            \n",
    "            val best_12_36 = best_12.withColumn(\"ast\", col(\"ast\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"blk\", col(\"blk\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"dreb\", col(\"dreb\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"fg3_pct\", col(\"fg3_pct\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"fg3a\", col(\"fg3a\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"fg3m\", col(\"fg3m\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"fg_pct\", col(\"fg_pct\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"fta\", col(\"fta\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"ftm\", col(\"ftm\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"oreb\", col(\"oreb\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"pf\", col(\"pf\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"pts\", col(\"pts\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"reb\", col(\"reb\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"stl\", col(\"stl\") / col(\"seconds\") * 2160)\n",
    "            .withColumn(\"turnover\", col(\"turnover\") / col(\"seconds\") * 2160)\n",
    "            // best_12_36.show()\n",
    "            \n",
    "            \n",
    "        }\n",
    "        catch{\n",
    "            case e: org.apache.spark.sql.AnalysisException => println(\"File not found\")\n",
    "        }\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
